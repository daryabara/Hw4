{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQN6QpgpnHJtTu9HNSSLFp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daryabara/Hw4/blob/main/Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n4iTUdSh0TSF",
        "outputId": "ae383340-f176-412d-cdd5-d502e3e59ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn nltk catboost matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Загружаю свой датасета\n",
        "data = pd.read_csv(\n",
        "    \"dataset_homework.csv\",\n",
        "    encoding=\"latin-1\",  # изменяю кодировку\n",
        "    names=[\"sentiment\", \"id\", \"date\", \"flag\", \"user\", \"text\"]  # пишем названия колонкам\n",
        ")\n",
        "data = data.sample ( n=10_000, random_state=42) #уменьшаю размерность датасета\n",
        "\n",
        "# показываю первые 1000 строк\n",
        "print(\"Первые 1000 твитов в датасете:\")\n",
        "print(data.head(1000))\n",
        "\n",
        "# просмотр информации информацию о датасете\n",
        "print(\"\\nИнформация о данных:\")\n",
        "print(data.info(1000))\n",
        "\n",
        "# Проверим сколько в датасете положительных и отрицтельных твитов\n",
        "print(\"\\nРаспределение тональностей:\")\n",
        "print(data[\"sentiment\"].value_counts())\n",
        "\n",
        "# в исходных данных отрицательные твиты имеют обозначение 0, положительные 4, для удобства преобразуем 4 в 1\n",
        "print(\"\\nПримеры текстов:\")\n",
        "print(\"Отрицательный твит (0):\", data[data[\"sentiment\"] == 0][\"text\"].iloc[0])\n",
        "data[\"sentiment\"] = data[\"sentiment\"].replace({4: 1})\n",
        "print(\"Положительный твит (4 → 1):\", data[data[\"sentiment\"] == 1][\"text\"].iloc[0])\n",
        "\n",
        "\n",
        "# Проверим изменения\n",
        "print(\"\\nПосле преобразования меток:\")\n",
        "print(data[\"sentiment\"].value_counts())\n",
        "\n",
        "# выведем первые 20 твитов с тональностью\n",
        "print(\"\\nПервые 20 твитов с тональностью:\")\n",
        "for i in range(20):\n",
        "    sentiment = \"Положительный\" if data[\"sentiment\"].iloc[i] == 1 else \"Отрицательный\"\n",
        "    print(f\"{i+1}. [{sentiment}] {data['text'].iloc[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5FQLNor0UVS",
        "outputId": "fbdcb15d-0fe1-4a6b-9e7b-a9c1face00d0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Первые 1000 твитов в датасете:\n",
            "         sentiment          id                          date      flag  \\\n",
            "541200           0  2200003196  Tue Jun 16 18:18:12 PDT 2009  NO_QUERY   \n",
            "750              0  1467998485  Mon Apr 06 23:11:14 PDT 2009  NO_QUERY   \n",
            "766711           0  2300048954  Tue Jun 23 13:40:11 PDT 2009  NO_QUERY   \n",
            "285055           0  1993474027  Mon Jun 01 10:26:07 PDT 2009  NO_QUERY   \n",
            "705995           0  2256550904  Sat Jun 20 12:56:51 PDT 2009  NO_QUERY   \n",
            "...            ...         ...                           ...       ...   \n",
            "338333           0  2014403427  Wed Jun 03 01:24:58 PDT 2009  NO_QUERY   \n",
            "109574           0  1824597501  Sun May 17 02:04:56 PDT 2009  NO_QUERY   \n",
            "1349309          4  2045195767  Fri Jun 05 10:22:33 PDT 2009  NO_QUERY   \n",
            "671510           0  2246888888  Fri Jun 19 18:16:30 PDT 2009  NO_QUERY   \n",
            "385755           0  2053668471  Sat Jun 06 05:19:48 PDT 2009  NO_QUERY   \n",
            "\n",
            "                    user                                               text  \n",
            "541200   LaLaLindsey0609             @chrishasboobs AHHH I HOPE YOUR OK!!!   \n",
            "750          sexygrneyes  @misstoriblack cool , i have no tweet apps  fo...  \n",
            "766711        sammydearr  @TiannaChaos i know  just family drama. its la...  \n",
            "285055       Lamb_Leanne  School email won't open  and I have geography ...  \n",
            "705995       yogicerdito                             upper airways problem   \n",
            "...                  ...                                                ...  \n",
            "338333          sydeshow  @girrlonthewing Ha, well you'd be surprised at...  \n",
            "109574          dineshah  Some dark clouds in #indiavotes #indiavotes09 ...  \n",
            "1349309        MDobson84  @wolfgnards awesome. Thanks for letting me kno...  \n",
            "671510         AnNa_HaLe  I left my heart @holdenbeach  Hoping to go bac...  \n",
            "385755       iPodman2008                           I wish I had the Sims 3   \n",
            "\n",
            "[1000 rows x 6 columns]\n",
            "\n",
            "Информация о данных:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 10000 entries, 541200 to 117202\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   sentiment  10000 non-null  int64 \n",
            " 1   id         10000 non-null  int64 \n",
            " 2   date       10000 non-null  object\n",
            " 3   flag       10000 non-null  object\n",
            " 4   user       10000 non-null  object\n",
            " 5   text       10000 non-null  object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 546.9+ KB\n",
            "None\n",
            "\n",
            "Распределение тональностей:\n",
            "sentiment\n",
            "0    5004\n",
            "4    4996\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Примеры текстов:\n",
            "Отрицательный твит (0): @chrishasboobs AHHH I HOPE YOUR OK!!! \n",
            "Положительный твит (4 → 1): on lunch....dj should come eat with me \n",
            "\n",
            "После преобразования меток:\n",
            "sentiment\n",
            "0    5004\n",
            "1    4996\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Первые 20 твитов с тональностью:\n",
            "1. [Отрицательный] @chrishasboobs AHHH I HOPE YOUR OK!!! \n",
            "2. [Отрицательный] @misstoriblack cool , i have no tweet apps  for my razr 2\n",
            "3. [Отрицательный] @TiannaChaos i know  just family drama. its lame.hey next time u hang out with kim n u guys like have a sleepover or whatever, ill call u\n",
            "4. [Отрицательный] School email won't open  and I have geography stuff on there to revise! *Stupid School* :'(\n",
            "5. [Отрицательный] upper airways problem \n",
            "6. [Отрицательный] Going to miss Pastor's sermon on Faith... \n",
            "7. [Положительный] on lunch....dj should come eat with me \n",
            "8. [Отрицательный] @piginthepoke oh why are you feeling like that? \n",
            "9. [Отрицательный] gahh noo!peyton needs to live!this is horrible \n",
            "10. [Положительный] @mrstessyman thank you glad you like it! There is a product review bit on the site  Enjoy knitting it!\n",
            "11. [Положительный] @PerezHilton Zach makes me pee sitting down! And I'm a grown gay man! \n",
            "12. [Положительный] to sum up my day in one word ......... kackered! \n",
            "13. [Положительный] @k9wkj Great minds think alike \n",
            "14. [Отрицательный] Is Poorly and in bed! \n",
            "15. [Положительный] @LilPecan Oh, that's really great  Here we have a small blizzard and also cold wind blows...\n",
            "16. [Положительный] @wizely lol, calm down.  i got a 30day loan offer for only 1500% \n",
            "17. [Положительный] i'm feeling quite sleepy today, wish i could stay in bed today...but OK! is my LAST YEAR, so let's go to school \n",
            "18. [Отрицательный] @nadalnews Yeah  Mathieu totally choked in the 3rd set to let Rog win as well. Djokovic played TERRIBLY.  \n",
            "19. [Отрицательный] ugh, morning's off to a rough start \n",
            "20. [Отрицательный] just bit my tongue \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "#загружаем из библиотеки nltk стоп слова лингвистическую БД английского\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "def clean_text(text):\n",
        "    # Удаляем ссылки, упоминания, спецсимволы\n",
        "    text = re.sub(r\"http\\S+|@\\w+|\\d+|[^\\w\\s]\", \"\", text)\n",
        "    text = text.lower().strip()\n",
        "\n",
        "    # Удаляем стоп-слова\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Лемматизация (приводим слова к базовой форме)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Применяем очистку к тексту твитов\n",
        "data[\"cleaned_text\"] = data[\"text\"].apply(clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhPK4N-5_5jJ",
        "outputId": "b736bf6f-ed0f-4568-8e61-6931da2bc572"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#смотрим на данные после манипуляций\n",
        "print(data.head(10))\n",
        "print(data['sentiment'].value_counts())\n",
        "\n",
        "# Создаём TF-IDF векторизатор (берём 5000 самых важных слов), анализируем 5000 самых частых слов из датасета\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf.fit_transform(data[\"cleaned_text\"])\n",
        "y = data[\"sentiment\"]\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки 70 на 30\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#примеры плохих и хороших слов\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "print(\"топ 100 слов\", feature_names[:100])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tepcGGmkBB4C",
        "outputId": "f846da11-c59f-4fa4-bcd2-6d6dea0a2d49"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         sentiment          id                          date      flag  \\\n",
            "541200           0  2200003196  Tue Jun 16 18:18:12 PDT 2009  NO_QUERY   \n",
            "750              0  1467998485  Mon Apr 06 23:11:14 PDT 2009  NO_QUERY   \n",
            "766711           0  2300048954  Tue Jun 23 13:40:11 PDT 2009  NO_QUERY   \n",
            "285055           0  1993474027  Mon Jun 01 10:26:07 PDT 2009  NO_QUERY   \n",
            "705995           0  2256550904  Sat Jun 20 12:56:51 PDT 2009  NO_QUERY   \n",
            "379611           0  2052380495  Sat Jun 06 00:32:16 PDT 2009  NO_QUERY   \n",
            "1189018          1  1983449090  Sun May 31 13:10:36 PDT 2009  NO_QUERY   \n",
            "667030           0  2245479748  Fri Jun 19 16:11:29 PDT 2009  NO_QUERY   \n",
            "93541            0  1770705699  Mon May 11 22:01:32 PDT 2009  NO_QUERY   \n",
            "1097326          1  1970386589  Sat May 30 03:39:34 PDT 2009  NO_QUERY   \n",
            "\n",
            "                    user                                               text  \\\n",
            "541200   LaLaLindsey0609             @chrishasboobs AHHH I HOPE YOUR OK!!!    \n",
            "750          sexygrneyes  @misstoriblack cool , i have no tweet apps  fo...   \n",
            "766711        sammydearr  @TiannaChaos i know  just family drama. its la...   \n",
            "285055       Lamb_Leanne  School email won't open  and I have geography ...   \n",
            "705995       yogicerdito                             upper airways problem    \n",
            "379611         Yengching         Going to miss Pastor's sermon on Faith...    \n",
            "1189018         jessig06            on lunch....dj should come eat with me    \n",
            "667030    felicityfuller   @piginthepoke oh why are you feeling like that?    \n",
            "93541        stephiiheyy    gahh noo!peyton needs to live!this is horrible    \n",
            "1097326        wyndwitch  @mrstessyman thank you glad you like it! There...   \n",
            "\n",
            "                                              cleaned_text  \n",
            "541200                                        ahhh hope ok  \n",
            "750                                   cool tweet apps razr  \n",
            "766711   know family drama lamehey next time u hang kim...  \n",
            "285055   school email wont open geography stuff revise ...  \n",
            "705995                                upper airway problem  \n",
            "379611                      going miss pastor sermon faith  \n",
            "1189018                                   lunchdj come eat  \n",
            "667030                                     oh feeling like  \n",
            "93541                gahh noopeyton need livethis horrible  \n",
            "1097326  thank glad like product review bit site enjoy ...  \n",
            "sentiment\n",
            "0    5004\n",
            "1    4996\n",
            "Name: count, dtype: int64\n",
            "топ 100 слов ['_xoxo' 'aa' 'aaaaahhhhhh' 'aaaah' 'aaaash' 'aaah' 'aaahhhh'\n",
            " 'aaarrrrgghhh' 'aagh' 'aahh' 'aahhh' 'aamir' 'aampe' 'aand' 'aanee' 'aaw'\n",
            " 'aawwwww' 'abba' 'abby' 'abis' 'able' 'absolutely' 'abt' 'abuse' 'ac'\n",
            " 'academy' 'accept' 'acceptable' 'access' 'accident' 'accidentally'\n",
            " 'accidently' 'accomplished' 'according' 'account' 'accounting' 'ache'\n",
            " 'aching' 'achy' 'across' 'act' 'acting' 'action' 'activity' 'actor'\n",
            " 'actual' 'actually' 'ad' 'adam' 'add' 'added' 'addict' 'addicted'\n",
            " 'addicting' 'addiction' 'addictive' 'adding' 'addition' 'address' 'admit'\n",
            " 'adopted' 'adorable' 'adore' 'adult' 'advantage' 'advert' 'advertising'\n",
            " 'advice' 'af' 'affect' 'afford' 'afraid' 'africa' 'afronum' 'aft'\n",
            " 'afternoon' 'afterparty' 'afterwards' 'againi' 'age' 'agent' 'agh' 'ago'\n",
            " 'agree' 'agreed' 'ah' 'aha' 'ahah' 'ahaha' 'ahahaa' 'ahead' 'ahem' 'ahh'\n",
            " 'ahhaha' 'ahhh' 'ahhhh' 'ahhhhh' 'ahhhhhh' 'ai' 'aid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "#будем тестировать 5 моделей, инициализируем модели\n",
        "models = {\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
        "    \"Extra Trees\": ExtraTreesClassifier(random_state=42),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis()\n",
        "}\n"
      ],
      "metadata": {
        "id": "ZhEE5Q-TBJdq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Обучение {name}...\")\n",
        "    #обучаем модели\n",
        "    model.fit(X_train.toarray(), y_train)\n",
        "    #предсказание на тестовых даданных\n",
        "    y_pred = model.predict(X_test.toarray())\n",
        "\n",
        "    # Считаем метрики, общая точность, баланс между precision recall, доля верных позитивных предсказаний(точность, сколько из положительных реально положительные), доля верно найденных поз твитов (полнота, солько реальных положительных твитов модель нашла)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"F1\": f1,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall\n",
        "    })\n",
        "\n",
        "# Сортируем по F1-score (чем выше, тем лучше)\n",
        "# Выводим таблицу сравнения моделей с сортировкой по F1-score(чем выше, те лучше модель)\n",
        "print(\"Результаты сравнения моделей (отсортированы по F1-score):\")\n",
        "print(results_df.sort_values('F1', ascending=False))\n",
        "\n",
        "# Автоматически выбираем лучшую модель\n",
        "best_model_name = results_df.loc[results_df['F1'].idxmax(), 'Model']\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "print(f\"\\n Лучшая модель: {best_model_name}\")\n",
        "print(f\"Её метрики: F1={results_df.loc[results_df['F1'].idxmax(), 'F1']:.3f}, Accuracy={results_df.loc[results_df['F1'].idxmax(), 'Accuracy']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAd1iRXdBO9m",
        "outputId": "9a74880c-0156-4ab1-ef10-2ff9e7ed191b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение Gradient Boosting...\n",
            "Обучение CatBoost...\n",
            "Обучение AdaBoost...\n",
            "Обучение Extra Trees...\n",
            "Обучение QDA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты сравнения моделей (отсортированы по F1-score):\n",
            "               Model  Accuracy        F1  Precision    Recall\n",
            "0  Gradient Boosting  0.674667  0.717854   0.634505  0.826411\n",
            "1           CatBoost  0.694400  0.716477   0.669131  0.771033\n",
            "3        Extra Trees  0.709867  0.716371   0.701736  0.731629\n",
            "2           AdaBoost  0.569600  0.675513   0.542636  0.894569\n",
            "4                QDA  0.556800  0.483530   0.580597  0.414271\n",
            "\n",
            " Лучшая модель: Gradient Boosting\n",
            "Её метрики: F1=0.718, Accuracy=0.675\n"
          ]
        }
      ]
    }
  ]
}